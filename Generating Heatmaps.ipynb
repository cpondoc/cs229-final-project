{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c966af",
   "metadata": {},
   "source": [
    "# Generating Heatmaps\n",
    "Code to set up heatmaps to gather insights from CNN training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12864ecd",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Import all necessary libraries for handling data and generating heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2041417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image \n",
    "import PIL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e564d11c",
   "metadata": {},
   "source": [
    "## Import Models\n",
    "In this case, we only need the pre-trained neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b792f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transferlearning import load_pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9626f814",
   "metadata": {},
   "source": [
    "## Import Dataset Class and Transforms\n",
    "Used to help load in the images for heatmap generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cdaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.dataset import ImageDataset\n",
    "from utilities.transforms import data_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa435ed",
   "metadata": {},
   "source": [
    "## Function to Generate Heatmap\n",
    "Uses the same workflow as testing the network, but instead of inferencing on each image, we save a heatmap, instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(transform, weights_path, batch_size, network, first, second):\n",
    "    # Loading in initial data\n",
    "    print(\"\\nLoading in data...\")\n",
    "    test_data = ImageDataset(\"test\", transform, 0.6, first, second)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "    print(\"Done loading in data.\")\n",
    "\n",
    "    # Test Loading\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels, img_names = next(dataiter)\n",
    "\n",
    "    # Loading in a new example of the neural net, and loading in the weights\n",
    "    net = network\n",
    "    if (torch.cuda.is_available()):\n",
    "        net.to('cuda')\n",
    "    net.load_state_dict(torch.load(weights_path))\n",
    "    \n",
    "    # Iterate through all of the images and their names and generate heatmaps\n",
    "    print(\"Generate Heatmaps...\")\n",
    "    cam_extractor = SmoothGradCAMpp(net)\n",
    "    for data in testloader:\n",
    "        images, labels, img_names = data\n",
    "        images_cuda, labels_cuda = images.cuda(), labels.cuda()\n",
    "        for image_cuda, img_name in zip(images_cuda, img_names):\n",
    "                # Generating the activation map\n",
    "                out = net(image_cuda.unsqueeze(0))\n",
    "                activation_map = cam_extractor(out.cpu().squeeze(0).argmax().item(), out.cpu())\n",
    "                \n",
    "                # Turning the image into a tensor\n",
    "                current_image = Image.open(img_name)\n",
    "                make_tensor = transforms.ToTensor()\n",
    "                current_image = make_tensor(current_image)\n",
    "                \n",
    "                # Cropping the image\n",
    "                crop_tensor = transforms.CenterCrop(224)\n",
    "                current_image = crop_tensor(current_image)\n",
    "                \n",
    "                # Overlaying heatmap on top of the image\n",
    "                result = overlay_mask(to_pil_image(current_image), to_pil_image(activation_map[0].cpu().squeeze(0), mode='F'), alpha=0.5)\n",
    "                plt.imshow(result)\n",
    "                plt.axis('off'); \n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Saving image\n",
    "                name = \"heatmaps/test/\" + \"heatmap_of_\"+img_name.split('/')[-1]\n",
    "                plt.savefig(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9205ffe5",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "Runs all of the necessary functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(weights, first, second):\n",
    "    # Define model and weights\n",
    "    model = load_pretrained_model()\n",
    "      \n",
    "    # Generate the necessary heatmaps\n",
    "    generate_heatmap(data_transforms['TransferLearning'], weights, 200, model, first, second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d670f",
   "metadata": {},
   "source": [
    "## Run all code!\n",
    "Runs all code to generate heatmaps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146992b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(weights='weights/TransferLearning-0.6-dallevsd.pth', first='dalle', second='stable-diffusion')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
